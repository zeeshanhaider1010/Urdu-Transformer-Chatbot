{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: imports & seed\n",
        "import csv\n",
        "from datetime import datetime\n",
        "import random, math, time\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "random.seed(42)\n"
      ],
      "metadata": {
        "id": "FTDfYXvkuBca"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: data loader with normalization\n",
        "def load_csv(path):\n",
        "    with open(path, 'r') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        data = [row for row in reader]\n",
        "    return reader.fieldnames, data\n",
        "\n",
        "def merge_and_sort(normal_csv, attack_csv, augment_devices=5):\n",
        "    h1, normal = load_csv(normal_csv)\n",
        "    h2, attack = load_csv(attack_csv)\n",
        "    for r in normal: r['label'] = 0\n",
        "    for r in attack: r['label'] = 1\n",
        "    combined = normal + attack\n",
        "    # Robust timestamp parsing: try several formats\n",
        "    for i, row in enumerate(combined):\n",
        "        d = row.get('Date','').strip()\n",
        "        t = row.get('Time','').strip()\n",
        "        parsed = None\n",
        "        for fmt in (\"%d-%b-%y, %H:%M:%S\", \"%d-%b-%y %H:%M:%S\", \"%Y-%m-%d %H:%M:%S\", \"%d/%m/%Y %H:%M:%S\"):\n",
        "            try:\n",
        "                parsed = datetime.strptime(f\"{d} {t}\", fmt)\n",
        "                break\n",
        "            except Exception:\n",
        "                continue\n",
        "        if parsed is None:\n",
        "            # fallback: try splitting commas\n",
        "            try:\n",
        "                parsed = datetime.strptime((d + \" \" + t).replace(',', ' '), \"%d %b %y %H:%M:%S\")\n",
        "            except Exception:\n",
        "                parsed = datetime(1970,1,1,0,0,0)\n",
        "        row['timestamp'] = parsed\n",
        "        # device id fallback\n",
        "        if not row.get('device_id'):\n",
        "            row['device_id'] = 'device_' + str((i % augment_devices) + 1)\n",
        "        # Fridge_Temperature normalization: scale to ~0-1 by dividing 40 (safe for fridge ranges)\n",
        "        ft = row.get('Fridge_Temperature', '').strip()\n",
        "        try:\n",
        "            val = float(ft)\n",
        "        except Exception:\n",
        "            try:\n",
        "                val = float(ft.replace(',','.'))\n",
        "            except Exception:\n",
        "                val = 0.0\n",
        "        row['Fridge_Temperature_norm'] = val / 40.0   # tuned normalization\n",
        "        tc = row.get('Temp_Condition','').strip().lower()\n",
        "        row['Temp_Condition_enc'] = 1.0 if 'high' in tc else 0.0\n",
        "    combined.sort(key=lambda x: x['timestamp'])\n",
        "    return combined\n",
        "\n",
        "def build_time_windows(parsed, window_size=5, step=1):\n",
        "    # Build sliding windows across time; windows are lists of sequential rows\n",
        "    windows = []\n",
        "    for i in range(0, max(1, len(parsed)-window_size+1), step):\n",
        "        seq_rows = parsed[i:i+window_size]\n",
        "        X_seq = []\n",
        "        lbl = 0\n",
        "        for r in seq_rows:\n",
        "            X_seq.append([r['Fridge_Temperature_norm'], r['Temp_Condition_enc']])\n",
        "            lbl = max(lbl, int(r['label']))\n",
        "        windows.append({'X_seq': X_seq, 'label': lbl, 'timestamp': seq_rows[-1]['timestamp']})\n",
        "    return windows\n",
        "\n",
        "# Quick run to ensure loader works (paths must be present in notebook)\n",
        "# headerless test example usage omitted here - run later after uploading CSVs.\n"
      ],
      "metadata": {
        "id": "aKv80_909vho"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: improved TGNN class with momentum and input-weight updates\n",
        "class TGNN:\n",
        "    def __init__(self, input_dim=2, hidden_dim=16, seed=0):\n",
        "        rnd = random.Random(seed)\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # weight matrices\n",
        "        self.W_in = [[rnd.uniform(-0.2,0.2) for _ in range(input_dim)] for __ in range(hidden_dim)]\n",
        "        self.W_h  = [[rnd.uniform(-0.2,0.2) for _ in range(hidden_dim)] for __ in range(hidden_dim)]\n",
        "        # output layer (trainable)\n",
        "        self.W_out = [rnd.uniform(-0.1,0.1) for _ in range(hidden_dim)]\n",
        "        self.b_out = 0.0\n",
        "        # momentum terms\n",
        "        self.v_out = [0.0]*hidden_dim\n",
        "        self.v_in = [[0.0]*input_dim for _ in range(hidden_dim)]\n",
        "\n",
        "    @staticmethod\n",
        "    def relu_vec(v): return [x if x>0 else 0.0 for x in v]\n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        # numeric-stable\n",
        "        if x >= 0:\n",
        "            z = math.exp(-x)\n",
        "            return 1.0/(1.0+z)\n",
        "        else:\n",
        "            z = math.exp(x)\n",
        "            return z/(1.0+z)\n",
        "\n",
        "    def matvec(self, M, v):\n",
        "        return [sum(M[i][j]*v[j] for j in range(len(v))) for i in range(len(M))]\n",
        "\n",
        "    def forward_full(self, X_seq):\n",
        "        # returns final hidden states H (list of vectors) and final h\n",
        "        h = [0.0]*self.hidden_dim\n",
        "        H_seq = []\n",
        "        for x in X_seq:\n",
        "            in_part = self.matvec(self.W_in, x)\n",
        "            hid_part = self.matvec(self.W_h, h)\n",
        "            h = self.relu_vec([in_part[i] + hid_part[i] for i in range(self.hidden_dim)])\n",
        "            H_seq.append(h[:])\n",
        "        return H_seq, h\n",
        "\n",
        "    def predict(self, X_seq):\n",
        "        _, h_final = self.forward_full(X_seq)\n",
        "        s = sum(h_final[i]*self.W_out[i] for i in range(self.hidden_dim)) + self.b_out\n",
        "        return self.sigmoid(s)\n",
        "\n",
        "    def train(self, windows, epochs=5, lr_out=0.05, lr_in=0.005, batch_size=32, momentum=0.9):\n",
        "        n = len(windows)\n",
        "        if n == 0:\n",
        "            return\n",
        "        for ep in range(1, epochs+1):\n",
        "            random.shuffle(windows)\n",
        "            total_loss = 0.0\n",
        "            for start in range(0, n, batch_size):\n",
        "                batch = windows[start:start+batch_size]\n",
        "                # accumulate grads\n",
        "                grad_w_out = [0.0]*self.hidden_dim\n",
        "                grad_b = 0.0\n",
        "                grad_W_in = [[0.0]*self.input_dim for _ in range(self.hidden_dim)]\n",
        "                for win in batch:\n",
        "                    X = win['X_seq']\n",
        "                    y = float(win['label'])\n",
        "                    H_seq, h_final = self.forward_full(X)\n",
        "                    p = self.predict(X)\n",
        "                    p = min(max(p, 1e-6), 1-1e-6)\n",
        "                    loss = - (y*math.log(p) + (1-y)*math.log(1-p))\n",
        "                    total_loss += loss\n",
        "                    # gradient scalar for output pre-sigmoid (dL/ds)\n",
        "                    grad_scalar = (p - y)\n",
        "                    # grad w.r.t W_out = grad_scalar * h_final\n",
        "                    for k in range(self.hidden_dim):\n",
        "                        grad_w_out[k] += grad_scalar * h_final[k]\n",
        "                    grad_b += grad_scalar\n",
        "                    # small gradient back to input weights (heuristic)\n",
        "                    # we propagate grad_scalar uniformly to W_in (not full backprop through nonlinearities)\n",
        "                    for i in range(self.hidden_dim):\n",
        "                        for j in range(self.input_dim):\n",
        "                            # scale by h_final to prioritize active neurons\n",
        "                            grad_W_in[i][j] += grad_scalar * (h_final[i] * 0.01) * X[-1][j]\n",
        "                # average grads\n",
        "                m = len(batch)\n",
        "                for k in range(self.hidden_dim):\n",
        "                    g = grad_w_out[k] / m\n",
        "                    # momentum update\n",
        "                    self.v_out[k] = momentum * self.v_out[k] + lr_out * g\n",
        "                    self.W_out[k] -= self.v_out[k]\n",
        "                self.b_out -= (grad_b / m) * lr_out\n",
        "                for i in range(self.hidden_dim):\n",
        "                    for j in range(self.input_dim):\n",
        "                        g_in = (grad_W_in[i][j] / m)\n",
        "                        self.v_in[i][j] = momentum * self.v_in[i][j] + lr_in * g_in\n",
        "                        self.W_in[i][j] -= self.v_in[i][j]\n",
        "            avg_loss = total_loss / n\n",
        "            print(f\"Epoch {ep} | Loss={avg_loss:.6f}\")\n"
      ],
      "metadata": {
        "id": "it3icCsD9yb_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: PPO agent improvements (epsilon exploration and stable update)\n",
        "class PPOAgent:\n",
        "    def __init__(self, state_dim=3, action_dim=4, seed=0):\n",
        "        rnd = random.Random(seed)\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        # actor weights: action_dim x state_dim\n",
        "        self.actor_w = [[rnd.uniform(-0.1,0.1) for _ in range(state_dim)] for _ in range(action_dim)]\n",
        "        self.actor_b = [0.0]*action_dim\n",
        "        # critic linear\n",
        "        self.critic_w = [rnd.uniform(-0.1,0.1) for _ in range(state_dim)]\n",
        "        self.critic_b = 0.0\n",
        "        # buffer\n",
        "        self.reset_buffer()\n",
        "        self.epsilon = 0.1  # exploration prob\n",
        "\n",
        "    def softmax(self, logits):\n",
        "        maxv = max(logits)\n",
        "        ex = [math.exp(l - maxv) for l in logits]\n",
        "        s = sum(ex)\n",
        "        return [e/s for e in ex]\n",
        "\n",
        "    def policy(self, state):\n",
        "        logits = [sum(self.actor_w[a][i]*state[i] for i in range(self.state_dim)) + self.actor_b[a] for a in range(self.action_dim)]\n",
        "        return self.softmax(logits)\n",
        "\n",
        "    def value(self, state):\n",
        "        return sum(self.critic_w[i]*state[i] for i in range(self.state_dim)) + self.critic_b\n",
        "\n",
        "    def select_action(self, state):\n",
        "        # epsilon-greedy style exploration mixed with softmax sampling\n",
        "        if random.random() < self.epsilon:\n",
        "            a = random.randrange(self.action_dim)\n",
        "            probs = [1.0/self.action_dim]*self.action_dim\n",
        "            return a, probs\n",
        "        probs = self.policy(state)\n",
        "        # categorical sample\n",
        "        r = random.random()\n",
        "        cum = 0.0\n",
        "        a = 0\n",
        "        for i,p in enumerate(probs):\n",
        "            cum += p\n",
        "            if r <= cum:\n",
        "                a = i\n",
        "                break\n",
        "        return a, probs\n",
        "\n",
        "    def store_transition(self, s, a, r, v):\n",
        "        self.buf_states.append(s)\n",
        "        self.buf_actions.append(a)\n",
        "        self.buf_rewards.append(r)\n",
        "        self.buf_values.append(v)\n",
        "\n",
        "    def reset_buffer(self):\n",
        "        self.buf_states = []\n",
        "        self.buf_actions = []\n",
        "        self.buf_rewards = []\n",
        "        self.buf_values = []\n",
        "\n",
        "    def compute_returns_advs(self, gamma=0.99):\n",
        "        R = []\n",
        "        G = 0.0\n",
        "        for r in reversed(self.buf_rewards):\n",
        "            G = r + gamma * G\n",
        "            R.insert(0, G)\n",
        "        advs = [R[i] - self.buf_values[i] for i in range(len(R))]\n",
        "        # normalize advs\n",
        "        if len(advs)>0:\n",
        "            mean = sum(advs)/len(advs)\n",
        "            var = sum((x-mean)**2 for x in advs)/len(advs)\n",
        "            std = math.sqrt(var) if var>0 else 1.0\n",
        "            advs = [(a-mean)/ (std + 1e-8) for a in advs]\n",
        "        return R, advs\n",
        "\n",
        "    def update(self, lr_actor=0.01, lr_critic=0.01, clip=0.2, epochs=3):\n",
        "        if not self.buf_states:\n",
        "            return\n",
        "        R, advs = self.compute_returns_advs()\n",
        "        for _ in range(epochs):\n",
        "            for i, s in enumerate(self.buf_states):\n",
        "                a = self.buf_actions[i]\n",
        "                adv = advs[i]\n",
        "                # update actor (policy gradient approx)\n",
        "                probs = self.policy(s)\n",
        "                one_hot = [0.0]*self.action_dim; one_hot[a]=1.0\n",
        "                for j in range(self.action_dim):\n",
        "                    grad_coeff = (one_hot[j] - probs[j]) * adv\n",
        "                    for k in range(self.state_dim):\n",
        "                        self.actor_w[j][k] += lr_actor * grad_coeff * s[k]\n",
        "                    self.actor_b[j] += lr_actor * grad_coeff\n",
        "                # critic update (MSE)\n",
        "                td = R[i] - self.buf_values[i]\n",
        "                for k in range(self.state_dim):\n",
        "                    self.critic_w[k] += lr_critic * td * s[k]\n",
        "                self.critic_b += lr_critic * td\n",
        "        self.reset_buffer()\n"
      ],
      "metadata": {
        "id": "CGZxJMV690mJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: honeypot\n",
        "class Honeypot:\n",
        "    def __init__(self):\n",
        "        self.captured = []\n",
        "    def attract(self, win):\n",
        "        self.captured.append(win)\n",
        "    def get_captured(self):\n",
        "        return len(self.captured)\n"
      ],
      "metadata": {
        "id": "hMPJEwiJ9218"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: helpers\n",
        "def extract_state(win_score, win):\n",
        "    # state: [win_score, avg_temp_norm, avg_cond]\n",
        "    avg_temp = sum(x[0] for x in win['X_seq']) / len(win['X_seq'])\n",
        "    avg_cond = sum(x[1] for x in win['X_seq']) / len(win['X_seq'])\n",
        "    # normalize avg_temp to small number (already normalized)\n",
        "    return [min(1.0, abs(win_score)), avg_temp, avg_cond]\n",
        "\n",
        "def evaluate_model(model, windows):\n",
        "    tp=tn=fp=fn=0\n",
        "    for w in windows:\n",
        "        p = model.predict(w['X_seq'])\n",
        "        pred = 1 if p>0.5 else 0\n",
        "        t = w['label']\n",
        "        if t==1 and pred==1: tp+=1\n",
        "        elif t==0 and pred==0: tn+=1\n",
        "        elif t==0 and pred==1: fp+=1\n",
        "        elif t==1 and pred==0: fn+=1\n",
        "    total = tp+tn+fp+fn if (tp+tn+fp+fn)>0 else 1\n",
        "    acc = (tp+tn)/total\n",
        "    prec = tp/(tp+fp+1e-8)\n",
        "    rec = tp/(tp+fn+1e-8)\n",
        "    f1 = 2*prec*rec/(prec+rec+1e-8)\n",
        "    return {'tp':tp,'tn':tn,'fp':fp,'fn':fn,'acc':acc,'prec':prec,'rec':rec,'f1':f1}\n",
        "\n",
        "def plot_rounds(accs, fname='federated_accuracy.png'):\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.plot(range(1,len(accs)+1), accs, marker='o', color='teal')\n",
        "    plt.title('Federated TGNN Accuracy per Round')\n",
        "    plt.xlabel('Round'); plt.ylabel('Accuracy'); plt.grid(True)\n",
        "    plt.savefig(fname, dpi=150)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "AVMmccZs945M"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: federated training loop (main)\n",
        "# Configuration - tune for Colab GPU runtime if you switch to vectorized versions later\n",
        "NORMAL_CSV = 'normal_data.csv'\n",
        "ATTACK_CSV = 'attack_data.csv'\n",
        "CLIENTS = 3\n",
        "FED_ROUNDS = 6\n",
        "WINDOW_SIZE = 5\n",
        "TGNN_EPOCHS = 6        # per-client local epochs\n",
        "TGNN_BATCH = 64\n",
        "PPO_ITERS = 20         # how many decisions per client per round\n",
        "LR_OUT = 0.08\n",
        "LR_IN  = 0.01\n",
        "\n",
        "print(\"Loading data...\")\n",
        "parsed = merge_and_sort(NORMAL_CSV, ATTACK_CSV, augment_devices=10)\n",
        "windows = build_time_windows(parsed, window_size=WINDOW_SIZE, step=1)\n",
        "print(\"Total windows:\", len(windows))\n",
        "\n",
        "# partition windows to clients (round-robin)\n",
        "client_windows = [[] for _ in range(CLIENTS)]\n",
        "for idx, w in enumerate(windows):\n",
        "    client_windows[idx % CLIENTS].append(w)\n",
        "\n",
        "# initialize models\n",
        "clients_tgnn = [TGNN(input_dim=2, hidden_dim=16, seed=100+i) for i in range(CLIENTS)]\n",
        "clients_ppo  = [PPOAgent(state_dim=3, action_dim=4, seed=200+i) for i in range(CLIENTS)]\n",
        "clients_hp   = [Honeypot() for _ in range(CLIENTS)]\n",
        "\n",
        "global_tgnn = deepcopy(clients_tgnn[0])\n",
        "global_ppo  = deepcopy(clients_ppo[0])\n",
        "\n",
        "acc_rounds = []\n",
        "\n",
        "for rnd in range(1, FED_ROUNDS+1):\n",
        "    print(\"\\n=== Federated Round %d/%d ===\" % (rnd, FED_ROUNDS))\n",
        "    local_tgnn_models = []\n",
        "    local_ppo_models  = []\n",
        "    round_start = time.time()\n",
        "    for cid in range(CLIENTS):\n",
        "        data = client_windows[cid]\n",
        "        if not data:\n",
        "            local_tgnn_models.append(clients_tgnn[cid])\n",
        "            local_ppo_models.append(clients_ppo[cid])\n",
        "            continue\n",
        "        # local TGNN training\n",
        "        print(f\" Client {cid+1}: TGNN training on {len(data)} windows...\")\n",
        "        clients_tgnn[cid].train(data, epochs=TGNN_EPOCHS, lr_out=LR_OUT, lr_in=LR_IN, batch_size=TGNN_BATCH, momentum=0.9)\n",
        "\n",
        "        # PPO interactions: sample windows and let PPO act with TGNN score\n",
        "        for it in range(PPO_ITERS):\n",
        "            w = random.choice(data)\n",
        "            p = clients_tgnn[cid].predict(w['X_seq'])\n",
        "            state = extract_state(p, w)\n",
        "            action, probs = clients_ppo[cid].select_action(state)\n",
        "            # reward rules\n",
        "            if w['label'] == 1:\n",
        "                if action == 2:\n",
        "                    clients_hp[cid].attract(w)\n",
        "                    reward = 6.0\n",
        "                elif action == 1:\n",
        "                    reward = 3.0\n",
        "                elif action == 0:\n",
        "                    reward = -3.0\n",
        "                else:\n",
        "                    reward = 1.0\n",
        "            else:\n",
        "                # normal traffic\n",
        "                if action == 1:   # false quarantine\n",
        "                    reward = -2.0\n",
        "                else:\n",
        "                    reward = 0.5\n",
        "            value = clients_ppo[cid].value(state)\n",
        "            clients_ppo[cid].store_transition(state, action, reward, value)\n",
        "        # update PPO locally\n",
        "        clients_ppo[cid].update(lr_actor=0.01, lr_critic=0.01, epochs=4)\n",
        "        local_tgnn_models.append(clients_tgnn[cid])\n",
        "        local_ppo_models.append(clients_ppo[cid])\n",
        "    # Server aggregation (FedAvg)\n",
        "    # Average W_out and b_out across local tgnns\n",
        "    n = len(local_tgnn_models)\n",
        "    if n>0:\n",
        "        # average W_out\n",
        "        for k in range(global_tgnn.hidden_dim):\n",
        "            global_tgnn.W_out[k] = sum(m.W_out[k] for m in local_tgnn_models)/n\n",
        "        global_tgnn.b_out = sum(m.b_out for m in local_tgnn_models)/n\n",
        "    # average actor weights for PPO\n",
        "    npp = len(local_ppo_models)\n",
        "    if npp>0:\n",
        "        for a in range(global_ppo.action_dim):\n",
        "            for k in range(global_ppo.state_dim):\n",
        "                global_ppo.actor_w[a][k] = sum(m.actor_w[a][k] for m in local_ppo_models)/npp\n",
        "            global_ppo.actor_b[a] = sum(m.actor_b[a] for m in local_ppo_models)/npp\n",
        "        for k in range(global_ppo.state_dim):\n",
        "            global_ppo.critic_w[k] = sum(m.critic_w[k] for m in local_ppo_models)/npp\n",
        "        global_ppo.critic_b = sum(m.critic_b for m in local_ppo_models)/npp\n",
        "\n",
        "    # distribute global back to clients (only output layer / actor/critic)\n",
        "    for cid in range(CLIENTS):\n",
        "        clients_tgnn[cid].W_out = global_tgnn.W_out[:]\n",
        "        clients_tgnn[cid].b_out = global_tgnn.b_out\n",
        "        clients_ppo[cid].actor_w = deepcopy(global_ppo.actor_w)\n",
        "        clients_ppo[cid].actor_b = deepcopy(global_ppo.actor_b)\n",
        "        clients_ppo[cid].critic_w = deepcopy(global_ppo.critic_w)\n",
        "        clients_ppo[cid].critic_b = global_ppo.critic_b\n",
        "\n",
        "    # evaluate aggregated model on full windows\n",
        "    metrics = evaluate_model(global_tgnn, windows)\n",
        "    acc_rounds.append(metrics['acc'])\n",
        "    print(\"Round %d done in %.1f s: acc=%.4f, prec=%.4f, rec=%.4f, f1=%.4f\" %\n",
        "          (rnd, time.time()-round_start, metrics['acc'], metrics['prec'], metrics['rec'], metrics['f1']))\n",
        "\n",
        "# final evaluation & plots\n",
        "final_metrics = evaluate_model(global_tgnn, windows)\n",
        "print(\"\\n=== Final evaluation ===\")\n",
        "print(final_metrics)\n",
        "plot_rounds(acc_rounds)\n",
        "print(\"Total honeypot captures per client:\", [hp.get_captured() for hp in clients_hp])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ww3XXgge98WJ",
        "outputId": "23dd0fda-1554-4a88-f3b1-4e9607b64440"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Total windows: 70381\n",
            "\n",
            "=== Federated Round 1/6 ===\n",
            " Client 1: TGNN training on 23461 windows...\n",
            "Epoch 1 | Loss=0.684279\n",
            "Epoch 2 | Loss=0.683789\n",
            "Epoch 3 | Loss=0.683732\n",
            "Epoch 4 | Loss=0.683706\n",
            "Epoch 5 | Loss=0.683689\n",
            "Epoch 6 | Loss=0.683746\n",
            " Client 2: TGNN training on 23460 windows...\n",
            "Epoch 1 | Loss=0.684372\n",
            "Epoch 2 | Loss=0.683698\n",
            "Epoch 3 | Loss=0.683705\n",
            "Epoch 4 | Loss=0.683694\n",
            "Epoch 5 | Loss=0.683686\n",
            "Epoch 6 | Loss=0.683659\n",
            " Client 3: TGNN training on 23460 windows...\n",
            "Epoch 1 | Loss=0.684222\n",
            "Epoch 2 | Loss=0.683745\n",
            "Epoch 3 | Loss=0.683730\n",
            "Epoch 4 | Loss=0.683638\n",
            "Epoch 5 | Loss=0.683648\n",
            "Epoch 6 | Loss=0.683666\n",
            "Round 1 done in 206.4 s: acc=0.5691, prec=0.0000, rec=0.0000, f1=0.0000\n",
            "\n",
            "=== Federated Round 2/6 ===\n",
            " Client 1: TGNN training on 23461 windows...\n",
            "Epoch 1 | Loss=0.683709\n",
            "Epoch 2 | Loss=0.683797\n",
            "Epoch 3 | Loss=0.683774\n",
            "Epoch 4 | Loss=0.683720\n",
            "Epoch 5 | Loss=0.683724\n",
            "Epoch 6 | Loss=0.683692\n",
            " Client 2: TGNN training on 23460 windows...\n",
            "Epoch 1 | Loss=0.683646\n",
            "Epoch 2 | Loss=0.683671\n",
            "Epoch 3 | Loss=0.683631\n",
            "Epoch 4 | Loss=0.683641\n",
            "Epoch 5 | Loss=0.683668\n",
            "Epoch 6 | Loss=0.683659\n",
            " Client 3: TGNN training on 23460 windows...\n",
            "Epoch 1 | Loss=0.683693\n",
            "Epoch 2 | Loss=0.683670\n",
            "Epoch 3 | Loss=0.683677\n",
            "Epoch 4 | Loss=0.683609\n",
            "Epoch 5 | Loss=0.683657\n",
            "Epoch 6 | Loss=0.683681\n",
            "Round 2 done in 208.9 s: acc=0.5691, prec=0.0000, rec=0.0000, f1=0.0000\n",
            "\n",
            "=== Federated Round 3/6 ===\n",
            " Client 1: TGNN training on 23461 windows...\n",
            "Epoch 1 | Loss=0.683652\n",
            "Epoch 2 | Loss=0.683709\n",
            "Epoch 3 | Loss=0.683710\n",
            "Epoch 4 | Loss=0.683524\n",
            "Epoch 5 | Loss=0.683706\n",
            "Epoch 6 | Loss=0.683727\n",
            " Client 2: TGNN training on 23460 windows...\n",
            "Epoch 1 | Loss=0.683563\n",
            "Epoch 2 | Loss=0.683642\n",
            "Epoch 3 | Loss=0.683653\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2144844475.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# local TGNN training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" Client {cid+1}: TGNN training on {len(data)} windows...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mclients_tgnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTGNN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR_OUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR_IN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTGNN_BATCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# PPO interactions: sample windows and let PPO act with TGNN score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-360173504.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, windows, epochs, lr_out, lr_in, batch_size, momentum)\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0mH_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-360173504.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_seq)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-360173504.py\u001b[0m in \u001b[0;36mforward_full\u001b[0;34m(self, X_seq)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_seq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0min_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mhid_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0min_part\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhid_part\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mH_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-360173504.py\u001b[0m in \u001b[0;36mmatvec\u001b[0;34m(self, M, v)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-360173504.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}